{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02.building-a-prototype.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJPZw7luiOuXuPeiqhZBQb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1NCK5Omuu9c"
      },
      "source": [
        "## The lifecycle of a Machine Learning project\n",
        "\n",
        "- Planning/choosing a goal\n",
        "- Data collection & labelling\n",
        "- Creating features & preprocessing\n",
        "- Training and optimization\n",
        "- Deployment\n",
        "\n",
        "## Planning\n",
        "\n",
        "Choosing what to work on and what is the measurement of success is the most important part of the project.\n",
        "\n",
        "Get help here! Ask domain experts, business people, meditate on it. Do spend some time to think about it. But don't linger for too long. Analysis paralysis is a very common phenomenon in the real world!\n",
        "\n",
        "## Prototyping a baseline model\n",
        "\n",
        "Jupyter notebooks are a great prototyping/experimentation tool. You can use a notebook(s) to get some quick ideas about the feasibility and performance of a model.\n",
        "\n",
        "After you get some results, you'll proceed to create a full-blown project containing the baseline model. This will be a lot of work, but some rewards you might expect are bug fixes, new ideas, and developing something that (hopefully) has a real-world impact.\n",
        "\n",
        "Next, we'll go over an example task of automating the decision of whether a bank customer has good or bad credit risk.\n",
        "\n",
        "### Getting your data\n",
        "\n",
        "If you haven't solved any real-world ML problems yet, you might believe that most datasets get stored as CSV files. While this format is great when learning, you'll often need to understand SQL, pickle, HDF5, Parquet, and many more. \n",
        "\n",
        "#### Labeling\n",
        "\n",
        "Sometimes your data will have labels, but it might not be exactly the data you need. Other times, you'll miss labels altogether. What can you do?\n",
        "\n",
        "Creating a labeling infrastructure will be time well spent, for sure. Increasing the data size and reducing the noise in your data (having less wrong data) will dramatically increase the predictive power of your model(s).\n",
        "\n",
        "You will always want more and cleaner data. So keep getting it, slowly but surely. At some point, you'll notice you start getting diminishing returns. Depending on the problem you're solving, it might be a good idea to focus on other issues in the project.\n",
        "\n",
        "#### Looking at the data\n",
        "\n",
        "This might sound boring and complete nonsense but go through different examples from the data. Can you figure out the labels for each one? Are the labels correct? Are the labels consistent?\n",
        "\n",
        "Remember, feeding your model with crappy data will give you garbage results. At this stage of the project, you don't want to deal with crap - there will be plenty later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLWr26p1hL3N",
        "outputId": "42f5a796-1eaf-4e9b-a560-d6017d890bd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "features, targets = datasets.fetch_openml(\n",
        "    name=\"credit-g\", \n",
        "    version=1, \n",
        "    return_X_y=True, \n",
        "    as_frame=True\n",
        ")\n",
        "\n",
        "features.shape, targets.shape"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 20), (1000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Gh4sIYjIYp",
        "outputId": "d6b28a41-e50e-4fcf-aecc-af7a7953a913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "features.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>checking_status</th>\n",
              "      <th>duration</th>\n",
              "      <th>credit_history</th>\n",
              "      <th>purpose</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>savings_status</th>\n",
              "      <th>employment</th>\n",
              "      <th>installment_commitment</th>\n",
              "      <th>personal_status</th>\n",
              "      <th>other_parties</th>\n",
              "      <th>residence_since</th>\n",
              "      <th>property_magnitude</th>\n",
              "      <th>age</th>\n",
              "      <th>other_payment_plans</th>\n",
              "      <th>housing</th>\n",
              "      <th>existing_credits</th>\n",
              "      <th>job</th>\n",
              "      <th>num_dependents</th>\n",
              "      <th>own_telephone</th>\n",
              "      <th>foreign_worker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>critical/other existing credit</td>\n",
              "      <td>radio/tv</td>\n",
              "      <td>1169.0</td>\n",
              "      <td>no known savings</td>\n",
              "      <td>&gt;=7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>male single</td>\n",
              "      <td>none</td>\n",
              "      <td>4.0</td>\n",
              "      <td>real estate</td>\n",
              "      <td>67.0</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "      <td>2.0</td>\n",
              "      <td>skilled</td>\n",
              "      <td>1.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0&lt;=X&lt;200</td>\n",
              "      <td>48.0</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>radio/tv</td>\n",
              "      <td>5951.0</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>1&lt;=X&lt;4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>female div/dep/mar</td>\n",
              "      <td>none</td>\n",
              "      <td>2.0</td>\n",
              "      <td>real estate</td>\n",
              "      <td>22.0</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "      <td>1.0</td>\n",
              "      <td>skilled</td>\n",
              "      <td>1.0</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>no checking</td>\n",
              "      <td>12.0</td>\n",
              "      <td>critical/other existing credit</td>\n",
              "      <td>education</td>\n",
              "      <td>2096.0</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>4&lt;=X&lt;7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>male single</td>\n",
              "      <td>none</td>\n",
              "      <td>3.0</td>\n",
              "      <td>real estate</td>\n",
              "      <td>49.0</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "      <td>1.0</td>\n",
              "      <td>unskilled resident</td>\n",
              "      <td>2.0</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>furniture/equipment</td>\n",
              "      <td>7882.0</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>4&lt;=X&lt;7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>male single</td>\n",
              "      <td>guarantor</td>\n",
              "      <td>4.0</td>\n",
              "      <td>life insurance</td>\n",
              "      <td>45.0</td>\n",
              "      <td>none</td>\n",
              "      <td>for free</td>\n",
              "      <td>1.0</td>\n",
              "      <td>skilled</td>\n",
              "      <td>2.0</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>delayed previously</td>\n",
              "      <td>new car</td>\n",
              "      <td>4870.0</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>1&lt;=X&lt;4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>male single</td>\n",
              "      <td>none</td>\n",
              "      <td>4.0</td>\n",
              "      <td>no known property</td>\n",
              "      <td>53.0</td>\n",
              "      <td>none</td>\n",
              "      <td>for free</td>\n",
              "      <td>2.0</td>\n",
              "      <td>skilled</td>\n",
              "      <td>2.0</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  checking_status  duration  ... own_telephone foreign_worker\n",
              "0              <0       6.0  ...           yes            yes\n",
              "1        0<=X<200      48.0  ...          none            yes\n",
              "2     no checking      12.0  ...          none            yes\n",
              "3              <0      42.0  ...          none            yes\n",
              "4              <0      24.0  ...          none            yes\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OwBps8WjnFd",
        "outputId": "8ce61b13-2586-4d87-d04e-0584a857b9ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "targets.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    good\n",
              "1     bad\n",
              "2    good\n",
              "3    good\n",
              "4     bad\n",
              "Name: class, dtype: category\n",
              "Categories (2, object): ['good', 'bad']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPGdO9NDjRvj",
        "outputId": "99977a48-79ce-465a-b6db-eec1401c24f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "targets.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "good    700\n",
              "bad     300\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2llz5gbS1EK"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9Cfb309plmW"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhg7NZ9Yqocc"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Ka2HAEqqnJ"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKdbVd65hRB3"
      },
      "source": [
        "### Note on reproducibility\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjHmi34rhUHs",
        "outputId": "18a5c27c-66e9-45af-a264-82e4c6482fff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED + 1)\n",
        "torch.manual_seed(RANDOM_SEED + 2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f89e95d9528>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPsMlYol0xR8"
      },
      "source": [
        "## Feature engineering\n",
        "\n",
        "One of the advantages of Deep Neural Networks is to automate the process of feature engineering. At least, that was the grand promise.\n",
        "\n",
        "In practice, adding manual features might significantly improve the performance of your model. But creating good features is black magic. Ideas for those come almost always from spending absurd amounts of time with the raw data.\n",
        "\n",
        "Start by thinking of a couple of features and encode them. Use classical ML algorithms (like Random Forest) to evaluate their importance. Those features will be prime candidates for inclusion in your Deep Learning model later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN9NAzHGRmv-"
      },
      "source": [
        "FEATURES = [\n",
        "  \"duration\", \n",
        "  \"credit_amount\", \n",
        "  \"age\", \n",
        "  \"existing_credits\", \n",
        "  \"residence_since\"\n",
        "]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjpbflwHTiIk"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  features[FEATURES], \n",
        "  targets, \n",
        "  test_size=0.2\n",
        ")\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "label_encoder = label_encoder.fit(y_train)\n",
        "\n",
        "X_train = X_train.to_numpy()\n",
        "y_train = label_encoder.transform(y_train)\n",
        "\n",
        "X_test = X_test.to_numpy()\n",
        "y_test = label_encoder.transform(y_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdNUJ8vcV6tG",
        "outputId": "07804ea0-a4db-4ffd-cfc5-a48725038f8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800, 5), (800,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8JOKrC_Ba5p",
        "outputId": "a8fe8659-9bb2-49b2-bd8e-b89b7f4afe4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((200, 5), (200,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuCyNBEtCJKN"
      },
      "source": [
        "## Training and evaluation\n",
        "\n",
        "Training a Deep Neural Net using any of the popular libraries for Deep Learning is relatively straightforward. That is given you keep playing with toy examples.\n",
        "\n",
        "In practice, the training might include a lot of hacks that change the generic process just a bit - enough to introduce bugs and write tons of incomprehensive code.\n",
        "\n",
        "Using a library like scikit-learn is a great first choice for building a baseline model. It takes very little time, the code is easier to understand and you can gain a lot of insight into the problem you're solving. \n",
        "\n",
        "Here's a quick example of how you can use a Random Forest classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtLtUfIacGkY"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=200)\n",
        "model = model.fit(X_train, y_train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYvnUJrpR-jR",
        "outputId": "022526f2-45bb-4d5f-8461-40e51682d1f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.score(X_test, y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.68"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t107ZfNb3NC"
      },
      "source": [
        "### Training a Deep Neural Net in PyTorch\n",
        "\n",
        "That is a great start, but we're interested in building a Neural Net. Let's create a simple one using PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdmVbSnCt5uk"
      },
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CreditTypeDataset(Dataset):\n",
        "  def __init__(self, features, labels):\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "      \n",
        "  def __getitem__(self, index):\n",
        "    return (\n",
        "      torch.from_numpy(self.features[index]).float(), \n",
        "      self.labels[index]\n",
        "    )\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxTyOFkSt7-2"
      },
      "source": [
        "dataset = CreditTypeDataset(X_train, y_train)\n",
        "data_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "features_batch, labels_batch = next(iter(data_loader))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LflHvaHluQbZ",
        "outputId": "13950838-d8f6-4fa1-d92e-c5c1db035c60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "features_batch"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.4000e+01, 1.2850e+03, 3.2000e+01, 1.0000e+00, 4.0000e+00],\n",
              "        [1.5000e+01, 1.5320e+03, 3.1000e+01, 1.0000e+00, 3.0000e+00],\n",
              "        [1.2000e+01, 5.2200e+02, 4.2000e+01, 2.0000e+00, 4.0000e+00],\n",
              "        [1.2000e+01, 1.8580e+03, 2.2000e+01, 1.0000e+00, 1.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSa9OdhIuSDp",
        "outputId": "5e19bc42-3824-41c8-a179-4fc01d4b78c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "labels_batch"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEanO7_kb4Ka"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class CreditTypeClassifierNet(nn.Module):\n",
        "\n",
        "  def __init__(self, n_features, n_credit_types):\n",
        "    super(CreditTypeClassifierNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(n_features, n_features * 2)\n",
        "    self.fc2 = nn.Linear(n_features * 2, n_credit_types)\n",
        "\n",
        "  def forward(self, x):    \n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "  def create_optimizer(self):\n",
        "    return optim.Adam(self.parameters(), lr=0.01)\n",
        "\n",
        "  def create_criterion(self):\n",
        "    return nn.CrossEntropyLoss()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si1cR-r5cnRo"
      },
      "source": [
        "model = CreditTypeClassifierNet(len(FEATURES), 2)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TexXGN8xcwc0",
        "outputId": "5336cd89-d2eb-44c7-e394-6d88f6541e2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CreditTypeClassifierNet(\n",
              "  (fc1): Linear(in_features=5, out_features=10, bias=True)\n",
              "  (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FTTUhETz-8-"
      },
      "source": [
        "class Phase:\n",
        "  TRAIN = \"train\"\n",
        "  TEST = \"test\"\n",
        "\n",
        "  values = [Phase.TRAIN, Phase.TEST]"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9c1_YnIZRUq"
      },
      "source": [
        "class Evaluator:\n",
        "\n",
        "  def __init__(self, criterion):\n",
        "    self.criterion = criterion\n",
        "\n",
        "  def eval(self, model, X, y, phase: Phase):\n",
        "    with torch.set_grad_enabled(phase == Phase.TRAIN):\n",
        "      model = model.train() if phase == Phase.TRAIN else model.eval()\n",
        "      outputs = model(X)\n",
        "      loss = self.criterion(outputs, y)\n",
        "\n",
        "      _, predicted = outputs.max(dim=1)\n",
        "      correct_count = torch.sum(predicted == y)\n",
        "\n",
        "      return loss, correct_count"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9iV5bB6f7yL"
      },
      "source": [
        "from collections import defaultdict, namedtuple\n",
        "\n",
        "Progress = namedtuple(\"Progress\", [\"loss\", \"accuracy\"])\n",
        "\n",
        "class ProgressLogger:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.progress = defaultdict(\n",
        "      lambda: {Phase.TRAIN: None, Phase.TEST: None}\n",
        "    )\n",
        "\n",
        "  @staticmethod\n",
        "  def _round(value, precision=3):\n",
        "    return np.round(value, precision)\n",
        "\n",
        "  def save_progress(self, epoch, phase, loss, accuracy):\n",
        "    self.progress[epoch][phase] = Progress(loss, accuracy)\n",
        "\n",
        "  def log(self, epoch):\n",
        "    print(f\"Epoch {epoch + 1}\")\n",
        "\n",
        "    train_progress = self.progress[epoch][Phase.TRAIN]\n",
        "    print(f\"Train: loss {ProgressLogger._round(train_progress.loss)} accuracy {ProgressLogger._round(train_progress.accuracy)}\")\n",
        "\n",
        "    test_progress = self.progress[epoch][Phase.TEST]\n",
        "    print(f\"Test: loss {ProgressLogger._round(test_progress.loss)} accuracy {ProgressLogger._round(test_progress.accuracy)}\")\n",
        "    print()"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYLsgRRZCYLH"
      },
      "source": [
        "class Trainer:\n",
        "\n",
        "  def __init__(self, train_dataset, test_dataset):\n",
        "\n",
        "    train_data_loader = DataLoader(train_dataset)\n",
        "    test_data_loader = DataLoader(test_dataset)\n",
        "\n",
        "    self.data_loaders = {\n",
        "        Phase.TRAIN: train_data_loader,\n",
        "        Phase.TEST: test_data_loader\n",
        "    }\n",
        "\n",
        "    self.dataset_sizes = {\n",
        "        Phase.TRAIN: len(train_dataset),\n",
        "        Phase.TEST: len(test_dataset)\n",
        "    }\n",
        "\n",
        "  def train(self, model, n_epochs):\n",
        "    optimizer = model.create_optimizer()\n",
        "\n",
        "    logger = ProgressLogger()\n",
        "\n",
        "    evaluator = Evaluator(model.create_criterion())\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "    \n",
        "      for phase in Phase.values:\n",
        "\n",
        "        phase_loss = 0.0\n",
        "        phase_correct = 0\n",
        "\n",
        "        for inputs, labels in self.data_loaders[phase]:\n",
        "\n",
        "          loss, correct_count = evaluator.eval(model, inputs, labels, phase)\n",
        "\n",
        "          if phase == Phase.TRAIN:\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "          phase_loss += loss.item() * inputs.size(0)\n",
        "          phase_correct += correct_count\n",
        "\n",
        "        epoch_loss = phase_loss / self.dataset_sizes[phase]\n",
        "        epoch_accuracy = phase_correct.double() / self.dataset_sizes[phase]\n",
        "\n",
        "        logger.save_progress(epoch, phase, epoch_loss, epoch_accuracy)\n",
        "\n",
        "      logger.log(epoch)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WulZLFHmECmq",
        "outputId": "e6c48bf9-7275-4a89-f7f3-ec983414d5ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dataset = CreditTypeDataset(X_train, y_train)\n",
        "test_dataset = CreditTypeDataset(X_test, y_test)\n",
        "\n",
        "trainer = Trainer(train_dataset, test_dataset)\n",
        "trainer.train(model, n_epochs=10)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "Train: loss 0.608 accuracy 0.70625\n",
            "Test: loss 0.632 accuracy 0.675\n",
            "\n",
            "Epoch 2\n",
            "Train: loss 0.608 accuracy 0.70625\n",
            "Test: loss 0.632 accuracy 0.675\n",
            "\n",
            "Epoch 3\n",
            "Train: loss 0.608 accuracy 0.70625\n",
            "Test: loss 0.632 accuracy 0.675\n",
            "\n",
            "Epoch 4\n",
            "Train: loss 0.608 accuracy 0.70625\n",
            "Test: loss 0.632 accuracy 0.675\n",
            "\n",
            "Epoch 5\n",
            "Train: loss 0.608 accuracy 0.70625\n",
            "Test: loss 0.632 accuracy 0.675\n",
            "\n",
            "Epoch 6\n",
            "Train: loss 0.608 accuracy 0.70625\n",
            "Test: loss 0.632 accuracy 0.675\n",
            "\n",
            "Epoch 7\n",
            "Train: loss 0.608 accuracy 0.70625\n",
            "Test: loss 0.632 accuracy 0.675\n",
            "\n",
            "Epoch 8\n",
            "Train: loss 0.608 accuracy 0.70625\n",
            "Test: loss 0.632 accuracy 0.675\n",
            "\n",
            "Epoch 9\n",
            "Train: loss 0.608 accuracy 0.70625\n",
            "Test: loss 0.632 accuracy 0.675\n",
            "\n",
            "Epoch 10\n",
            "Train: loss 0.608 accuracy 0.70625\n",
            "Test: loss 0.632 accuracy 0.675\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOZBSAhhj4do"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "How well will your model do in production? To answer this question, you need answers to the following two:\n",
        "\n",
        "- What resources (CPU, GPU, RAM and disk space) do my model need to run? What is the expected response time?\n",
        "- How well will the predicted values match the real ones?\n",
        "\n",
        "You can usually answer the first question using a variety of tools from the software development world (like time, top and htop). However, you need to take into account the size of the input data. If you're loading into memory large text or image data, they might overflow and crash your program. Make sure you know the bounds of your data.\n",
        "\n",
        "How good your model predictions are? A wide variety of statistical tests are available to evaluate the performance of different models. And they are very good at what they do. But having large amounts of data changes the game a little bit. You can use simple tools like accuracy, confusion matrix, precision, recall and apply appropriate thresholding. Proper evaluation of your model can be done only if you're intimately familiar with the domain.\n",
        "\n",
        "One critical step in the process is looking at errors. Where your model makes errors? You should manually go through some errors to get a feel for them. How do you solve those? One simple and effective way to make your model better - add more data, matching the conditions where the model makes errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQFeb6yF033N"
      },
      "source": [
        "## Deployment\n",
        "\n",
        "Deploying your model allows you to get your work to your users. It might be that millions will use it (given you work at a company like Google) or just you. Either way, you'll need to make your model available.\n",
        "\n",
        "The most common way of deploying your model is behind a REST API. You can also embed it into a user's device (building a mobile app for iOS or Android).\n",
        "\n",
        "### Building an API"
      ]
    }
  ]
}